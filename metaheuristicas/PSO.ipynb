{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Particle Swarm Optimizer_ (PSO)\n",
    "\n",
    "PSO es un método de optimización inspirado en el patrón de comportamiento de parvadas de aves y cardúmenes de peces. Imagina una parvada de palomas circulando al rededor de un área en donde pueden oler comida. La paloma que se encuentre más cerca de la fuente de comida será aquella que zurreé más fuerte. Todas las demás palomas se apresurarán en irse hacia donde se encuentra ést. Si cualquier otra ave se acerca más a la fuente de comida, entonces esta chillará más fuerte y todas se apresurarán en irse hacia donde se encuentra ésta. El evento continuará ocurriendo y las aves irán agrupandose al rededor de la fuente de comida, cada vez más y más cerca, hasta que alguna encuentre el alimento.\n",
    "    \n",
    "Las primeras ideas fueron propuestas por [Kennedy y Eberhart (1995)](https://ieeexplore.ieee.org/document/494215) al igual que las primeras simulaciones ([1995](https://ieeexplore.ieee.org/document/488968), 1996).\n",
    "\n",
    "El algoritmo implementado en el programa realizado en el presente trabajo se obtuvo de *Riccardo Pili, James Kennedy y Tim Blackwell, _\"Particle swarm optimization. An overview._\"* ([2007](https://link.springer.com/article/10.1007/s11721-007-0002-0)). En su trabajo la evolución del algoritmo, desde su introducción en 1995, es discutida. En él se presentan algunas versiones y aspectos del algoritmo, así como el efecto de los parámetros utlizados. **Si se desea profundizar más sobre el PSO, así como los distintos métodos y cuando utilizarlos, el origen y significado de las ecuaciones y parámetros utilizados, etc; favor de acudir al artículo mencionado así como a sus referencias.**\n",
    "\n",
    "## Panorama general\n",
    "\n",
    "En PSO, $n$ número de entidades (partículas) son colocadas en el _espacio de búsqueda_<sup>[1](#espacio)</sup> de la _función objetivo_<sup>[2](#func)</sup>. Cada individuo está compuesto por vectores $D$-dimensionales, en donde la dimensión está dada por la dimensionalidad del espacio de búsqueda. Éstos contienen la información de de la posición actual $\\textbf{x}_i$, la mejor posición anterior<sup>[3](#optimizar)</sup> $\\textbf{p}_i$ y la velocidad $\\textbf{v}_i$, de la $i$-ésima partícula. **La mejor posición anterior $\\textbf{p}_i$, es aquella que pertenece a la de la i-ésima partícula con el mejor valor calculado hasta ahora de la función objetivo $pbest_i$**.\n",
    "<br>En cada iteración la posición actual $\\textbf{x}_i$ es evaluada en la función objetivo. Si la posición actual es mejor que $\\textbf{p}_i$, entonces guardamos o actualizamos $\\textbf{p}_i$ con la posición $\\textbf{x}_i$ y el valor de la función objetivo evaluada en dicha posición en $pbest_i$.\n",
    "\n",
    "### **¿Es necesario guardar la mejor posición $\\textbf{p}_i$?**\n",
    "### **¿No basta con simplemente guardar su valor $pbest_i$?**\n",
    "\n",
    "Retomando la introducción, las partículas se deben de ir agrupando como se agrupan las aves, posicionandose hacia donde se encuentra aquella que chilla más, o mejor dicho, hacia la posición $\\textbf{p}_i$. Podemos intuír que las posiciones de todas las partículas en el ejambre deben ser actualizadas en dirección de $\\textbf{p}_i$ , de manera tal que la partículas tomen valores al rededor de esa posición y ésta sea afinada a través de cada iteración. \n",
    "\n",
    "Es muy importante considerar que existen funciones que cuentan una gran cantidad de mínimos locales y que además se complican con la dimensionalidad. Por ello es que muchas partículas son arrojadas para explorar el espacio, en vez de una sola; de manera que se puede evitar, en lo mejor de lo posible, permanecer en mínimos locales . Si alguna partícula cae en un mínimo, entonces todas las demás se moveran hacia éste en base a $\\textbf{p}_i$. Si alguna otra cae en otro mínimo local, menor al anterior, entonces comenzarán a dirigirse hacia una posición con un mejor $pbest_i$. Ésto ocurrirá iterativamente hasta que se cumpla algún criterio<sup>[4](#criterios)</sup> y con suerte se encuentre el mínimo global, o una buena aproximación de éste.\n",
    "\n",
    "El siguiente algoritmo es una adaptación del agoritmo original, en el cual únicamente se modifica la manera en la que originalmente es calculada la velocidad. Éste fue desarrollado por Clerk y Kennedy ([2002]{https://ieeexplore.ieee.org/document/985692}). Clerk y Kennedy incluyeron _coeficientes de constricción_ para controlar la convergencia del algoritmo dado que desde un principio se notaron casos en los cuales el calculo de las velocidades comenzaba hacer que las partículas comenzaran a diverger. Para ello originalmente se introduce un parámetro de velocidad máxima que impida que la velocidad crezca más de $V_{max}$.\n",
    "\n",
    "El cálculo **original** de la velocidad está dado por:\n",
    "\n",
    "$$\\textbf{v}_i \\leftarrow \\textbf{v}_i + \\textbf{U}(0,\\phi_1) \\otimes (\\textbf{p}_i-\\textbf{x}_i) +  \\textbf{U}(0,\\phi_2) \\otimes (\\textbf{p}_g-\\textbf{x}_i) $$\n",
    "\n",
    "En donde $\\textbf{U}(0,\\phi _i)$ representa un vector de números aleatorios uniformemente distribuidos en $[0,\\phi]$, generado de manera aleatoria en cada iteración y para cada partícula.\n",
    "\n",
    "Utilizando los _coeficientes de constricción_, la expresión anterior se convierte en:\n",
    "\n",
    "$$\\textbf{v}_i \\leftarrow \\chi (\\textbf{v}_i + \\textbf{U}(0,\\phi_1) \\otimes (\\textbf{p}_i-\\textbf{x}_i) +  \\textbf{U}(0,\\phi_2) \\otimes (\\textbf{p}_g-\\textbf{x}_i) ) $$\n",
    "\n",
    "En donde:\n",
    "\n",
    "$$ \\chi = \\frac{2}{\\phi - 2 + (\\phi^2-4\\phi)^{1/2}} $$\n",
    "\n",
    "y $\\phi=\\phi_1+\\phi_2$.\n",
    "\n",
    "Usualmente se utilizan valores de $\\phi = 4.1$ con $\\phi_1=\\phi_2$. Esta constricción de Clerc finalmente hará que las partículas converjan sin necesidad de controlar una $V_{max}$.\n",
    "\n",
    "Otro método, y quizás el más comúnmente utilizado para controlar la busqueda reduciendo la importancia del parámetro $V_{max}$, es introducir un término llamado _peso inercial_ $w$ (Shi and Eberhart [1998](https://ieeexplore.ieee.org/document/699146)), de la siguiente manera:\n",
    "\n",
    "$$\\textbf{v}_i \\leftarrow w\\textbf{v}_i + \\textbf{U}(0,\\phi_1) \\otimes (\\textbf{p}_i-\\textbf{x}_i) +  \\textbf{U}(0,\\phi_2) \\otimes (\\textbf{p}_g-\\textbf{x}_i) $$\n",
    "\n",
    "En el presente algoritmo se utiliza la constricción de Clerc, pero se mapea al uso del peso inercial mediante $w \\leftrightarrow \\chi$. Esto es:\n",
    "\n",
    "* $w = 0.7298$\n",
    "* $\\phi_1 = \\phi_2 = 1.49618$\n",
    "\n",
    "## Algoritmo\n",
    "\n",
    "1. *Inicializar la población de partíulas*.\n",
    "* *Ciclo*\n",
    "    * **Evaluar** cada partícula en la función objetivo.\n",
    "    * **Comparar** el mejor valor de la función objetivo, con el de todas las partículas.\n",
    "    * **Guardar o actualizar** el mejor valor encontrado de la función objetivo y su respectiva posición en el espacio.\n",
    "    * **Actualizar** posición y velocidad de cada partícula:\n",
    " \n",
    "    \\begin{cases} \n",
    "    \\text{$\\textbf{v}_i$} &\\leftarrow\\quad\\text{$\\textbf{v}_i + \\textbf{U}(0,\\phi_1) \\otimes (\\textbf{p}_i-\\textbf{x}_i) +  \\textbf{U}(0,\\phi_2) \\otimes (\\textbf{p}_g-\\textbf{x}_i) $}, & (1) \\\\\n",
    "    \\text{$\\textbf{x}_i$} &\\leftarrow\\quad\\text{$\\textbf{x}_i+\\textbf{v}_i$} & (2)\n",
    "    \\end{cases}\n",
    "    \n",
    "En donde $\\textbf{U}(0,\\phi _i)$ representa un vector de números aleatorios uniformemente distribuidos en $[0,\\phi]$, generado de manera aleatoria en cada iteración y para cada partícula.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><div><p><a name=\"espacio\"><sup>1</sup></a><sub> El espacio de busqueda hace referencia al dominio de la misma</sub></p>\n",
    "<p><a name=\"func\"><sup>2</sup></a><sub> La función objetivo es aquella que se busca optmimizar</sub></p>\n",
    "<p><a name=\"optimizar\"><sup>3</sup></a><sub> Comúnmente en PSO lo que se busca es minimizar la función objetivo.</sub></p>\n",
    "<p><a name=\"criterios\"><sup>4</sup></a><sub> Usualmente de error y/o un número máximo de iteraciones.</sub></p></div>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación en python\n",
    "\n",
    "Para la implementación y prueba del código se utilizarán dos funciones prueba:\n",
    "\n",
    "1. [Rastrigin](https://www.sfu.ca/~ssurjano/rastr.html) (3 dimensiones)\n",
    "2. [Goldstein-Price](https://www.sfu.ca/~ssurjano/goldpr.html) (2 dimensiones)\n",
    "\n",
    "y se utilizará lo mejor de lo posible la misma notación introducida anteriormente para los parámetros y las variables con el objetivo de facilitar el seguimiento del artículo anteriormente mencionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Función de Rastrigin\n",
    "\n",
    "Se importan primeramente las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rnd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se declaran algunas variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3           # número de dimensiones\n",
    "npart = 50      # número de partículas\n",
    "nepochs = 100   # máximas iteraciones\n",
    "w = 0.7298      # inertia weight \n",
    "phi = 1.49618   # acceleration coefficients or stiffness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen algunas constantes para simplificar los cálculos de la función de Rastrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2.0 * np.pi\n",
    "A = 10\n",
    "An = A * D\n",
    "# condiciones de frontera\n",
    "a = -5.12\n",
    "b = 5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función\n",
    "\n",
    "$$ f(\\textbf{x}) = AD + \\sum^D_{i=1}[x_i^2 - Acos(2\\pi x_i)] $$\n",
    "\n",
    "en donde $A = 10$ con $-5.12\\leq x_i \\leq 5.12$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x):\n",
    "    t1 = np.square(x)\n",
    "    t2 = A * np.cos(k * x)\n",
    "    res = An + np.sum(t1 - t2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una clase para contener la información de los vectores correspondientes a cada partícula, como un objeto de la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self):\n",
    "        # vector de posición\n",
    "        self.x = np.array(D)\n",
    "        # vector de velocidad\n",
    "        self.v = np.array(D)\n",
    "        \n",
    "        # posiciones y velocidades iniciales aleatorias\n",
    "        for i in range(D):\n",
    "            self.x = rnd.uniform(a,b,D)\n",
    "            self.v = rnd.uniform(a,b,D)\n",
    "        \n",
    "        # mejor posición anterior inicial es la actual \n",
    "        self.p = np.copy(self.x)\n",
    "        # mejor valor de la partícula es el actual\n",
    "        self.val = evaluate(self.p)\n",
    "        \n",
    "    def compute_velocity(self, pg):\n",
    "        t1 = w * self.v\n",
    "        U1 = rnd.uniform(0,phi,D)\n",
    "        t2 = U1 * (self.p - self.x)\n",
    "        U2 = rnd.uniform(0,phi,D)\n",
    "        t3 = U2 * (pg - self.x)\n",
    "        self.v = t1 + t2 + t3\n",
    "\n",
    "    def compute_position(self):\n",
    "        self.x += self.v\n",
    "\n",
    "    def update_pbests(self):\n",
    "        self.p = np.copy(self.x)\n",
    "        self.val = evaluate(self.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente es una función para manejar todas las acciones del PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO():\n",
    "    # ----------------------------------\n",
    "    # INICIALIZACION\n",
    "    \n",
    "    # lista para albergar el enjambre\n",
    "    swarm = []\n",
    "    # arreglo para la mejor posición en el enjambre\n",
    "    pg = np.empty(D)\n",
    "    # llenar el enjambre de partículas\n",
    "    for i in range(npart):\n",
    "        swarm.append(Particle())\n",
    "        \n",
    "        # designar a la primer partícula como la mejor en el enjambre\n",
    "        if i == 0:\n",
    "            # mejores valores en el enjambre\n",
    "            pg = np.copy(swarm[i].x)\n",
    "            sbest = swarm[i].val\n",
    "        \n",
    "        # comparar con la partícula anterior\n",
    "        if i > 0 and swarm[i].val < sbest:\n",
    "            # si la partícula actual es mejor que la anterior\n",
    "            sbest = swarm[i].val\n",
    "            pg = np.copy(swarm[i].x)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # CICLO\n",
    "    \n",
    "    epoch = 0\n",
    "    while epoch < nepochs:\n",
    "        for i in range(npart):\n",
    "            # Computar nueva velocidad\n",
    "            swarm[i].compute_velocity(pg)\n",
    "\n",
    "            # Computar nueva posición\n",
    "            swarm[i].compute_position()\n",
    "\n",
    "            # evaluar en la función objetivo \n",
    "            swarm[i].val = evaluate(swarm[i].x)\n",
    "            \n",
    "            # actualizar los mejores valores del enjambre hasta ahora\n",
    "            swarm[i].update_pbests()\n",
    "            if swarm[i].val < sbest:\n",
    "                pg = np.copy(swarm[i].x)\n",
    "                sbest = swarm[i].val\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    return pg, sbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se sabe que la función de Rastrigin tiene como valor mínimo:\n",
    "\n",
    "$$f(0,0,0) = 0$$\n",
    "\n",
    "De hecho para cualquier dimensión los mínimos globales de la función y su valor en dicha posición son $\\textbf{x}=0$ y $f(\\textbf{x})=0$, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "optimal solution found at:\n",
      "[0.00000224 0.00005547 0.00000808]\n",
      "\n",
      "With value:\t6.243075425516054e-07\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimal = PSO()\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(\"\\n\\noptimal solution found at:\\n{0}\\n\\n\"\n",
    "        \"With value:\\t{1}\\n\\n\".format(optimal[0], optimal[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Función de Goldstein-Price\n",
    "\n",
    "Ahora se define la función de Goldstein-Price\n",
    "\n",
    "$$ f(x,y) = [ 1 + (x + y + 1)^2 (19 - 14x + 3x^2 - 14y + 6xy + 3y^2)]\n",
    "[30 + (2x-3y)^2 (18 - 32 + 12x^2 + 48y 0 36xy + 27y^2)]$$\n",
    "\n",
    "en donde se sabe que el mínimo global se encuentra en\n",
    "\n",
    "$$ f(0,-1) = 3 $$\n",
    "\n",
    "dentro del dominio $ -2 \\leq x,y \\leq 2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x):\n",
    "    t1 = 1 + np.sum(x)\n",
    "    t1 *= t1\n",
    "    t2 = 19 - 14*x[0] + 3*x[0]*x[0] - 14*x[1] + 6*x[0]*x[1] + 3*x[1]*x[1]\n",
    "    t3 = (2*x[0] - 3*x[1])**2\n",
    "    t4 = 18 - 32*x[0] + 12*x[0]**2 + 48*x[1] - 36*x[0]*x[1] + 27*x[1]**2\n",
    "    res = (1 + t1*t2) * (30 + t3*t4)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2           # número de dimensiones\n",
    "npart = 50      # número de partículas\n",
    "nepochs = 100   # máximas iteraciones\n",
    "w = 0.7298      # inertia weight \n",
    "phi = 1.49618   # acceleration coefficients or stiffness:\n",
    "# dominio al que se restringe la función\n",
    "a = -2.0\n",
    "b = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "optimal solution found at:\n",
      "[ 0.00000021 -0.99999986]\n",
      "\n",
      "With value:\t3.0000000000129368\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimal = PSO()\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(\"\\n\\noptimal solution found at:\\n{0}\\n\\n\"\n",
    "        \"With value:\\t{1}\\n\\n\".format(optimal[0], optimal[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
